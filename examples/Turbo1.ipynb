{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example of TuRBO-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turbo import Turbo1\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up an optimization problem class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Levy:\n",
    "    def __init__(self, dim=10):\n",
    "        self.dim = dim\n",
    "        self.lb = -5 * np.ones(dim)\n",
    "        self.ub = 10 * np.ones(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == self.dim\n",
    "        assert x.ndim == 1\n",
    "        assert np.all(x <= self.ub) and np.all(x >= self.lb)\n",
    "        w = 1 + (x - 1.0) / 4.0\n",
    "        val = np.sin(np.pi * w[0]) ** 2 + \\\n",
    "            np.sum((w[1:self.dim - 1] - 1) ** 2 * (1 + 10 * np.sin(np.pi * w[1:self.dim - 1] + 1) ** 2)) + \\\n",
    "            (w[self.dim - 1] - 1) ** 2 * (1 + np.sin(2 * np.pi * w[self.dim - 1])**2)\n",
    "        return val\n",
    "\n",
    "f = Levy(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Turbo optimizer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m turbo1 = Turbo1(\n\u001b[32m      2\u001b[39m     f=f,  \u001b[38;5;66;03m# Handle to objective function\u001b[39;00m\n\u001b[32m      3\u001b[39m     lb=f.lb,  \u001b[38;5;66;03m# Numpy array specifying lower bounds\u001b[39;00m\n\u001b[32m      4\u001b[39m     ub=f.ub,  \u001b[38;5;66;03m# Numpy array specifying upper bounds\u001b[39;00m\n\u001b[32m      5\u001b[39m     n_init=\u001b[32m10\u001b[39m,  \u001b[38;5;66;03m# Number of initial bounds from an Latin hypercube design\u001b[39;00m\n\u001b[32m      6\u001b[39m     max_evals = \u001b[32m300\u001b[39m,  \u001b[38;5;66;03m# Maximum number of evaluations\u001b[39;00m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m#objective_tol = -1,\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m#improvement_tol = -1,\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m#max_time = 15,\u001b[39;00m\n\u001b[32m     10\u001b[39m     batch_size=\u001b[32m10\u001b[39m,  \u001b[38;5;66;03m# How large batch size TuRBO uses\u001b[39;00m\n\u001b[32m     11\u001b[39m     verbose=\u001b[32m1\u001b[39m,  \u001b[38;5;66;03m# Print information from each batch\u001b[39;00m\n\u001b[32m     12\u001b[39m     use_ard=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# Set to true if you want to use ARD for the GP kernel\u001b[39;00m\n\u001b[32m     13\u001b[39m     max_cholesky_size=\u001b[32m2000\u001b[39m,  \u001b[38;5;66;03m# When we switch from Cholesky to Lanczos\u001b[39;00m\n\u001b[32m     14\u001b[39m     n_training_steps=\u001b[32m50\u001b[39m,  \u001b[38;5;66;03m# Number of steps of ADAM to learn the hypers\u001b[39;00m\n\u001b[32m     15\u001b[39m     min_cuda=\u001b[32m1024\u001b[39m,  \u001b[38;5;66;03m# Run on the CPU for small datasets\u001b[39;00m\n\u001b[32m     16\u001b[39m     device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# \"cpu\" or \"cuda\"\u001b[39;00m\n\u001b[32m     17\u001b[39m     dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# float64 or float32\u001b[39;00m\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TuRBO/turbo/turbo_1.py:74\u001b[39m, in \u001b[36mTurbo1.__init__\u001b[39m\u001b[34m(self, f, lb, ub, n_init, max_evals, batch_size, verbose, use_ard, max_cholesky_size, n_training_steps, min_cuda, device, dtype)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m n_init > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n_init, \u001b[38;5;28mint\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m batch_size > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(verbose, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(use_ard, \u001b[38;5;28mbool\u001b[39m)\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m max_cholesky_size >= \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m n_training_steps >= \u001b[32m30\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n_training_steps, \u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "turbo1 = Turbo1(\n",
    "    f=f,  # Handle to objective function\n",
    "    lb=f.lb,  # Numpy array specifying lower bounds\n",
    "    ub=f.ub,  # Numpy array specifying upper bounds\n",
    "    n_init=10,  # Number of initial bounds from an Latin hypercube design\n",
    "    max_evals = 300,  # Maximum number of evaluations\n",
    "    #objective_tol = -1,\n",
    "    #improvement_tol = -1,\n",
    "    #max_time = 15,\n",
    "    batch_size=10,  # How large batch size TuRBO uses\n",
    "    verbose=1,  # Print information from each batch\n",
    "    use_ard=True,  # Set to true if you want to use ARD for the GP kernel\n",
    "    max_cholesky_size=2000,  # When we switch from Cholesky to Lanczos\n",
    "    n_training_steps=50,  # Number of steps of ADAM to learn the hypers\n",
    "    min_cuda=1024,  # Run on the CPU for small datasets\n",
    "    device=\"cpu\",  # \"cpu\" or \"cuda\"\n",
    "    dtype=\"float64\",  # float64 or float32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo1.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all evaluations from Turbo and print the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = turbo1.X  # Evaluated points\n",
    "fX = turbo1.fX  # Observed values\n",
    "ind_best = np.argmin(fX)\n",
    "f_best, x_best = fX[ind_best], X[ind_best, :]\n",
    "\n",
    "print(\"Best value found:\\n\\tf(x) = %.3f\\nObserved at:\\n\\tx = %s\" % (f_best, np.around(x_best, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the progress\n",
    "Each trust region is independent and finds different solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "plt.plot(fX, 'b.', ms=10)  # Plot all evaluated points as blue dots\n",
    "plt.plot(np.minimum.accumulate(fX), 'r', lw=3)  # Plot cumulative minimum as a red line\n",
    "plt.xlim([0, len(fX)])\n",
    "plt.ylim([0, 30])\n",
    "plt.title(\"10D Levy function\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
